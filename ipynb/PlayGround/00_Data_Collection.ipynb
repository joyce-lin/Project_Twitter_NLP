{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "#from lib.twitter_keys import keys\n",
    "!pip install twitter tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = '0vqmq8vkBGwFaOOQJPkk75wj9'\n",
    "CONSUMER_SECRET = 'F6FLN4514JXyq8IPmtIFQA9TI5TqJ3XFcxATrRhZ2GVQNDNhHf'\n",
    "ACCESS_TOKEN = '862710988822372352-dC0d1LzeLd5wodTA3BqjRtT9U2f7TQR'\n",
    "ACCESS_SECRET = 'J71AYBbH69nJCkqwPKV0YrqTDiUqjz0yOhNDJ9BGZ02kz'\n",
    "keys = {\n",
    "'CONSUMER_KEY': '0vqmq8vkBGwFaOOQJPkk75wj9',\n",
    "'CONSUMER_SECRET': 'F6FLN4514JXyq8IPmtIFQA9TI5TqJ3XFcxATrRhZ2GVQNDNhHf',\n",
    "'ACCESS_TOKEN': '862710988822372352-dC0d1LzeLd5wodTA3BqjRtT9U2f7TQR',\n",
    "'ACCESS_SECRET': 'J71AYBbH69nJCkqwPKV0YrqTDiUqjz0yOhNDJ9BGZ02kz'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os,sys,inspect\n",
    "from time import sleep\n",
    "#currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "#parentdir = os.path.dirname(currentdir)\n",
    "#sys.path.insert(0,parentdir)\n",
    "\n",
    "\n",
    "import json\n",
    "from twitter import Twitter, OAuth, TwitterHTTPError, TwitterStream\n",
    "CONSUMER_KEY = '0vqmq8vkBGwFaOOQJPkk75wj9'\n",
    "CONSUMER_SECRET = 'F6FLN4514JXyq8IPmtIFQA9TI5TqJ3XFcxATrRhZ2GVQNDNhHf'\n",
    "ACCESS_TOKEN = '862710988822372352-dC0d1LzeLd5wodTA3BqjRtT9U2f7TQR'\n",
    "ACCESS_SECRET = 'J71AYBbH69nJCkqwPKV0YrqTDiUqjz0yOhNDJ9BGZ02kz'\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### geo bounding for tweet location----------------------------------------------------####\n",
    "\n",
    "los_angeles = \"-118.670883,33.733477,-117.695847,34.290126\"\n",
    "Santa_Monica = \"-118.514757,33.980857,-118.417253,34.065264\"\n",
    "Dallas = \"-96.904907,32.761906,-96.684917,33.080035\"\n",
    "Midland_Odessa = \"-103.1575,31.4849,-101.5178,32.3591\"\n",
    "Sacramento_east = \"-121.8658,38.445,-120.2618,39.3598\"\n",
    "SFO = \"-122.5319,37.5751,-122.3438,37.824\"\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### connect to postgres----------------------------------------------------------------####\n",
    "\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "\n",
    "\n",
    "### ------------------------------------------------------------------------------------####\n",
    "### cleaning text ----------------------------------------------------------------------####\n",
    "\n",
    "def cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "\n",
    "    #text = re.sub(\":\",\"\\:\",text)\n",
    "    return text\n",
    "\n",
    "### -------------------------------------------------------------------------------------####\n",
    "### cleaning tweet ----------------------------------------------------------------------####\n",
    "\n",
    "#from spacy.en import STOP_WORDS\n",
    "#from spacy.en import English\n",
    "#import nltk\n",
    "#nlp = English()\n",
    "def tweet_cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub(r'http\\S+', '',text)\n",
    "    text = re.sub(r'@\\S+', '',text)\n",
    "    \n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    text = re.sub('\\n',' ',text) \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = re.sub(emoji_pattern, '', text)    \n",
    "#    text = ' '.join([i.lemma_ for i in nlp(text) \n",
    "#                   if i.orth_ not in STOP_WORDS])\n",
    "    \n",
    "    return text\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### Collecting tweets------------------------------------------------------------------####\n",
    "\n",
    "\n",
    "\n",
    "oauth = OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_stream = TwitterStream(auth=oauth)\n",
    "#iterator = twitter_stream.statuses.filter(locations=Santa_Monica+','+\\\n",
    "#                                          Midland_Odessa+','+Dallas+','+\\\n",
    "#                                          Sacramento_east+','+SFO)\n",
    "iterator = twitter_stream.statuses.filter(locations=los_angeles)\n",
    "tweet_count = 300000\n",
    "\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "for tweet in iterator:\n",
    "    if tweet['lang'] == 'en':   \n",
    "        tweet_count -= 1  \n",
    "\n",
    "        try:\n",
    "            id_str = str(tweet['id_str'])\n",
    "        except:    \n",
    "            pass\n",
    "        try:\n",
    "            screen_name = tweet['user']['screen_name']\n",
    "        except:\n",
    "            screen_name = None\n",
    "\n",
    "        tweet_content = cleaner(tweet['text'])\n",
    "        cleaned_tweet = tweet_cleaner(tweet['text'])\n",
    "        date = tweet['created_at'][26:30]+'-'+tweet['created_at'][4:7]+'-'+tweet['created_at'][8:10]\n",
    "        time = tweet['created_at'][11:19]\n",
    "        \n",
    "        screen_name = tweet['user']['screen_name']\n",
    "        retweeted = tweet['retweeted']\n",
    "        retweet_count = tweet['retweet_count']\n",
    "        created_at = tweet['created_at']\n",
    "        #date_time = \"to_timestamp(concat(substring('{}',27,4),'-',substring('{}',5,3),'-',\\\n",
    "        #        substring'({}',9,2),' ',substring('{}',11,9)),\\'YYYY-Mon-DD HH24:MI:SS') at time zone \\'UTC'\"\\\n",
    "        #        .format(created_at,created_at,created_at,created_at)\n",
    "        date_time = tweet['created_at'][26:30]+'-'+\\\n",
    "                    tweet['created_at'][4:7]+'-'+tweet['created_at'][8:10]+' '+tweet['created_at'][11:19]\n",
    "        get_hashtags = lambda tweet: \" \".join([i for i in tweet.split() if ('#' in i)])\n",
    "        hashtags1 = get_hashtags(tweet_content)\n",
    "        hashtags1 = re.sub('\\W',' ',hashtags1)\n",
    "        hashtags1 = re.sub('\\s+',' ',hashtags1)\n",
    "        try: \n",
    "            if len(hashtags1) > 1:\n",
    "                hashtags = hashtags1\n",
    "            else:\n",
    "                hashtags = None\n",
    "        except:\n",
    "            hashtags = None\n",
    "        try:\n",
    "            location =  cleaner(tweet['place']['full_name'])\n",
    "        except:\n",
    "            location = None\n",
    "        try:\n",
    "            country = tweet['place']['country']\n",
    "        except:\n",
    "            country = None\n",
    "        try:\n",
    "            place_type = tweet['place']['place_type']\n",
    "        except:\n",
    "            place_type = None\n",
    "        try:\n",
    "            latitude = tweet[\"geo\"][\"coordinates\"][0]\n",
    "            longitude = tweet[\"geo\"][\"coordinates\"][1]\n",
    "        except:\n",
    "            latitude = 0.0 \n",
    "            longitude = 0.0  \n",
    "        usr = tweet['user']\n",
    "        lang = tweet['lang']\n",
    "        try:\n",
    "            time_zone = cleaner(tweet['user']['time_zone'])\n",
    "        except:\n",
    "            time_zone = None    \n",
    "        sql_insert = '''insert into tweets \n",
    "                            (\n",
    "                                id,\n",
    "                                screen_name,\n",
    "                                tweet_content,\n",
    "                                cleaned_tweet,\n",
    "                                hashtags,\n",
    "                                created_at,\n",
    "                                date,\n",
    "                                time,\n",
    "                                date_time,\n",
    "                                retweeted,\n",
    "                                retweet_count,\n",
    "                                location,\n",
    "                                country,\n",
    "                                place_type,\n",
    "                                latitude,\n",
    "                                longitude, \n",
    "                                time_zone,\n",
    "                                lang\n",
    "                            )\n",
    "                        values\n",
    "                            ('{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}');\n",
    "                     '''.format(id_str,\n",
    "                                screen_name,\n",
    "                                tweet_content,\n",
    "                                cleaned_tweet,\n",
    "                                hashtags,\n",
    "                                created_at,\n",
    "                                date,\n",
    "                                time,\n",
    "                                date_time,\n",
    "                                retweeted,\n",
    "                                retweet_count,\n",
    "                                location,\n",
    "                                country,\n",
    "                                place_type,\n",
    "                                latitude,\n",
    "                                longitude,\n",
    "                                time_zone,\n",
    "                                lang\n",
    "                               )\n",
    "        print(str(tweet_count)+' '+ screen_name+ ':  '+ tweet_content)\n",
    "        #print(latitude,longitude)\n",
    "        cur.execute(sql_insert)\n",
    "            \n",
    "\n",
    "        conn.commit()\n",
    "        if tweet_count <= 0:\n",
    "            break\n",
    "    else:\n",
    "        pass\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "update tweets set time = TO_TIMESTAMP(substring(created_at,11,9), 'HH24:MI:SS') where time is null;\n",
    "\n",
    "select created_at, concat(substring(created_at,27,4),'-',substring(created_at,5,3),'-',substring(created_at,9,2)) from tweets limit 1;\n",
    "\n",
    "update tweets set date = TO_date(concat(substring(created_at,27,4),'-',substring(created_at,5,3),'-',substring(created_at,9,2)), 'YYYY-Mon-DD') where date is null;\n",
    "\n",
    "update tweets set date_time = to_timestamp(concat(substring(created_at,27,4),'-',substring(created_at,5,3),'-',\n",
    "substring(created_at,9,2),' ',substring(created_at,11,9)),'YYYY-Mon-DD HH24:MI:SS') at time zone 'UTC';\n",
    "\n",
    "'''update tweets set date_time = to_timestamp(concat(substring(created_at,27,4),'-',substring(created_at,5,3),'-',\n",
    "substring(created_at,9,2),' ',substring(created_at,11,9)),'YYYY-Mon-DD HH24:MI:SS') at time zone 'UTC' where date_time is null;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet['created_at'][26:30]+'-'+tweet['created_at'][4:7]+'-'+tweet['created_at'][8:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet['created_at'][11:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "select count(*) from tweets;\n",
    "\n",
    "##### create able\n",
    "select * into tweets_bkup_0607 from tweets;\n",
    "\n",
    "CREATE TABLE tweets (\n",
    "    id TEXT, \n",
    "    tweet_content TEXT, \n",
    "    entities TEXT,\n",
    "    retweeted TEXT,\n",
    "    created_at TEXT,\n",
    "    regin TEXT,\n",
    "    country TEXT,\n",
    "    place_type TEXT,\n",
    "    geo_enabled boolean,\n",
    "    geo text,\n",
    "    time_zone TEXT,\n",
    "    lang TEXT,\n",
    "    usr text\n",
    "    );\n",
    "    \n",
    "##### drop table\n",
    "drop table tweets_bkup_0606;\n",
    "\n",
    "##### set ID/ Index\n",
    "alter table tweets alter column id set not null;\n",
    "alter table tweets add unique (id);\n",
    "\n",
    "create index on tweets (id);\n",
    "create index on tweets (tweet_content);\n",
    "\n",
    "##### clean table\n",
    "select count (*) from tweets where hashtags = 'None';\n",
    "select count (*) from tweets where hashtags is null;\n",
    "update tweets set hashtags = NULL where hashtags = 'None';\n",
    "\n",
    "select count(*) from tweets where lang != 'en';\n",
    "delete from tweets where lang != 'en';\n",
    "\n",
    "##### Docker - psql\n",
    "docker exec -it mypostgres psql postgres postgres\n",
    "\n",
    "##### In psql\n",
    "\\d tweets\n",
    "\\dt\n",
    "\\q\n",
    "\n",
    "##### get cloumns\n",
    "SELECT * FROM Northwind.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'tweets';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='54.191.217.176'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "cur = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "#cur.execute(sql_create)\n",
    "#cur.execute(sql_drop)\n",
    "#cur.execute(sql_insert)\n",
    "#conn.commit()\n",
    "cur.execute(sql_select)\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'place': {'country_code': 'US', 'attributes': {}, 'full_name': 'Los Angeles, CA', 'country': 'United States', 'name': 'Los Angeles', 'id': '3b77caf94bfc81fe', 'place_type': 'city', 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-118.668404, 33.704538], [-118.668404, 34.337041], [-118.155409, 34.337041], [-118.155409, 33.704538]]]}, 'url': 'https://api.twitter.com/1.1/geo/id/3b77caf94bfc81fe.json'}, 'is_quote_status': True, 'in_reply_to_user_id_str': None, 'entities': {'user_mentions': [], 'symbols': [], 'urls': [{'indices': [27, 50], 'expanded_url': 'https://twitter.com/memekaay/status/873241262438064128', 'url': 'https://t.co/7cwpyAW6w8', 'display_url': 'twitter.com/memekaay/statu‚Ä¶'}], 'hashtags': []}, 'geo': None, 'text': 'Merciiiii meena joooonamüíìüòç https://t.co/7cwpyAW6w8', 'retweeted': False, 'id': 873242356543246336, 'in_reply_to_user_id': None, 'possibly_sensitive': False, 'in_reply_to_screen_name': None, 'display_text_range': [0, 26], 'favorite_count': 0, 'in_reply_to_status_id_str': None, 'coordinates': None, 'quoted_status_id_str': '873241262438064128', 'user': {'lang': 'en', 'protected': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/864725976495702017/OK7MjIzM_normal.jpg', 'contributors_enabled': False, 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/864725976495702017/OK7MjIzM_normal.jpg', 'name': 'kimia', 'id': 1526688224, 'profile_text_color': '000000', 'notifications': None, 'is_translator': False, 'favourites_count': 19046, 'geo_enabled': True, 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'created_at': 'Tue Jun 18 04:21:39 +0000 2013', 'default_profile_image': False, 'statuses_count': 6882, 'location': 'San Diego, CA', 'url': None, 'profile_link_color': 'E81C4F', 'following': None, 'profile_use_background_image': False, 'profile_sidebar_fill_color': '000000', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1526688224/1495320225', 'followers_count': 289, 'time_zone': 'Tijuana', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'screen_name': 'kimijalali', 'verified': False, 'id_str': '1526688224', 'friends_count': 144, 'listed_count': 3, 'profile_background_tile': False, 'follow_request_sent': None, 'profile_sidebar_border_color': '000000', 'utc_offset': -25200, 'profile_background_color': '000000', 'default_profile': False, 'description': 'salam üáÆüá∑üíÉüèΩüå∑üíê insta: kimia_jalali'}, 'contributors': None, 'in_reply_to_status_id': None, 'lang': 'in', 'id_str': '873242356543246336', 'truncated': False, 'quoted_status': {'place': None, 'is_quote_status': False, 'in_reply_to_user_id_str': '1526688224', 'entities': {'user_mentions': [{'name': 'kimia', 'id': 1526688224, 'screen_name': 'kimijalali', 'id_str': '1526688224', 'indices': [0, 11]}], 'symbols': [], 'urls': [], 'hashtags': []}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'text': '@kimijalali Ghorboone oon khandat beram man khoshgel üíñ', 'retweeted': False, 'id': 873241262438064128, 'in_reply_to_user_id': 1526688224, 'in_reply_to_screen_name': 'kimijalali', 'display_text_range': [12, 54], 'favorite_count': 1, 'in_reply_to_status_id_str': '873225443247177729', 'coordinates': None, 'user': {'lang': 'en', 'protected': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/869560964378542084/gGBOWYeN_normal.jpg', 'contributors_enabled': False, 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/869560964378542084/gGBOWYeN_normal.jpg', 'name': 'Meena', 'id': 623981165, 'profile_text_color': '333333', 'notifications': None, 'is_translator': False, 'favourites_count': 12884, 'geo_enabled': True, 'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/794300559/e6a0cafcfffef7b0995c200fc87512a5.jpeg', 'created_at': 'Sun Jul 01 18:38:14 +0000 2012', 'default_profile_image': False, 'statuses_count': 11891, 'location': None, 'url': None, 'profile_link_color': '080808', 'following': None, 'profile_use_background_image': True, 'profile_sidebar_fill_color': 'DDEEF6', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/623981165/1496822956', 'followers_count': 672, 'time_zone': 'Arizona', 'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/794300559/e6a0cafcfffef7b0995c200fc87512a5.jpeg', 'screen_name': 'memekaay', 'verified': False, 'id_str': '623981165', 'friends_count': 237, 'listed_count': 7, 'profile_background_tile': True, 'follow_request_sent': None, 'profile_sidebar_border_color': 'FFFFFF', 'utc_offset': -25200, 'profile_background_color': '090A0A', 'default_profile': False, 'description': 'üáÆüá∑ #BlackLivesMatter #FreePalestine'}, 'contributors': None, 'in_reply_to_status_id': 873225443247177729, 'lang': 'hi', 'truncated': False, 'id_str': '873241262438064128', 'retweet_count': 0, 'geo': None, 'created_at': 'Fri Jun 09 18:11:55 +0000 2017', 'favorited': False, 'filter_level': 'low'}, 'timestamp_ms': '1497032176515', 'retweet_count': 0, 'quoted_status_id': 873241262438064128, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'created_at': 'Fri Jun 09 18:16:16 +0000 2017', 'favorited': False, 'filter_level': 'low'}\n",
      "None\n",
      "{'place': {'country_code': 'US', 'attributes': {}, 'full_name': 'Santa Monica, CA', 'country': 'United States', 'name': 'Santa Monica', 'id': '59612bd882018c51', 'place_type': 'city', 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-118.517358, 33.995177], [-118.517358, 34.050199], [-118.443482, 34.050199], [-118.443482, 33.995177]]]}, 'url': 'https://api.twitter.com/1.1/geo/id/59612bd882018c51.json'}, 'is_quote_status': False, 'in_reply_to_user_id_str': None, 'entities': {'user_mentions': [], 'symbols': [], 'urls': [], 'hashtags': []}, 'geo': None, 'text': \"On a film set making good money. Can't complain. üòÅ\", 'retweeted': False, 'id': 873242358594191361, 'in_reply_to_user_id': None, 'in_reply_to_screen_name': None, 'favorite_count': 0, 'in_reply_to_status_id_str': None, 'id_str': '873242358594191361', 'user': {'lang': 'en', 'protected': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/843675129687166976/-qTqWYIN_normal.jpg', 'contributors_enabled': False, 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/843675129687166976/-qTqWYIN_normal.jpg', 'name': 'Chris Cordova Cinema', 'id': 136969401, 'profile_text_color': '333333', 'notifications': None, 'is_translator': False, 'favourites_count': 15872, 'geo_enabled': True, 'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/378800000129615595/tmzdjZGt.jpeg', 'created_at': 'Sun Apr 25 12:04:03 +0000 2010', 'default_profile_image': False, 'statuses_count': 23165, 'location': 'Always Editing... /LA #FILM', 'url': 'http://ChrisCordova.com', 'profile_link_color': 'DD2E44', 'following': None, 'profile_use_background_image': True, 'profile_sidebar_fill_color': 'EFEFEF', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/136969401/1487590683', 'followers_count': 3067, 'time_zone': 'Pacific Time (US & Canada)', 'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/378800000129615595/tmzdjZGt.jpeg', 'screen_name': 'DirectorChris', 'verified': False, 'id_str': '136969401', 'friends_count': 664, 'listed_count': 104, 'profile_background_tile': False, 'follow_request_sent': None, 'profile_sidebar_border_color': 'FFFFFF', 'utc_offset': -25200, 'profile_background_color': '131516', 'default_profile': False, 'description': '‚ö°Ô∏èWriter. Director. Editor üé¨Insta ‚û°Ô∏è http://Instagram.com/ChrisCordovaPresents YouTube ‚èØhttps://youtu.be/hlNYbMt-6ic'}, 'contributors': None, 'in_reply_to_status_id': None, 'lang': 'en', 'truncated': False, 'coordinates': None, 'timestamp_ms': '1497032177004', 'retweet_count': 0, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'created_at': 'Fri Jun 09 18:16:17 +0000 2017', 'favorited': False, 'filter_level': 'low'}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os,sys,inspect\n",
    "from time import sleep\n",
    "#currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "#parentdir = os.path.dirname(currentdir)\n",
    "#sys.path.insert(0,parentdir)\n",
    "\n",
    "\n",
    "import json\n",
    "from twitter import Twitter, OAuth, TwitterHTTPError, TwitterStream\n",
    "CONSUMER_KEY = '0vqmq8vkBGwFaOOQJPkk75wj9'\n",
    "CONSUMER_SECRET = 'F6FLN4514JXyq8IPmtIFQA9TI5TqJ3XFcxATrRhZ2GVQNDNhHf'\n",
    "ACCESS_TOKEN = '862710988822372352-dC0d1LzeLd5wodTA3BqjRtT9U2f7TQR'\n",
    "ACCESS_SECRET = 'J71AYBbH69nJCkqwPKV0YrqTDiUqjz0yOhNDJ9BGZ02kz'\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### geo bounding for tweet location----------------------------------------------------####\n",
    "\n",
    "los_angeles = \"-118.670883,33.733477,-117.695847,34.290126\"\n",
    "Santa_Monica = \"-118.514757,33.980857,-118.417253,34.065264\"\n",
    "Dallas = \"-96.904907,32.761906,-96.684917,33.080035\"\n",
    "Midland_Odessa = \"-103.1575,31.4849,-101.5178,32.3591\"\n",
    "Sacramento_east = \"-121.8658,38.445,-120.2618,39.3598\"\n",
    "SFO = \"-122.5319,37.5751,-122.3438,37.824\"\n",
    "[[-118.517358, 33.995177],\n",
    " [-118.517358, 34.050199],\n",
    " [-118.443482, 34.050199],\n",
    " [-118.443482, 33.995177]]\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### connect to postgres----------------------------------------------------------------####\n",
    "\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "\n",
    "\n",
    "### ------------------------------------------------------------------------------------####\n",
    "### cleaning text ----------------------------------------------------------------------####\n",
    "\n",
    "def cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "\n",
    "    #text = re.sub(\":\",\"\\:\",text)\n",
    "    return text\n",
    "\n",
    "### -------------------------------------------------------------------------------------####\n",
    "### cleaning tweet ----------------------------------------------------------------------####\n",
    "\n",
    "#from spacy.en import STOP_WORDS\n",
    "#from spacy.en import English\n",
    "#import nltk\n",
    "#nlp = English()\n",
    "def tweet_cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub(r'http\\S+', '',text)\n",
    "    text = re.sub(r'@\\S+', '',text)\n",
    "    \n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    text = re.sub('\\n',' ',text) \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = re.sub(emoji_pattern, '', text)    \n",
    "#    text = ' '.join([i.lemma_ for i in nlp(text) \n",
    "#                   if i.orth_ not in STOP_WORDS])\n",
    "    \n",
    "    return text\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### Collecting tweets------------------------------------------------------------------####\n",
    "\n",
    "\n",
    "\n",
    "oauth = OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_stream = TwitterStream(auth=oauth)\n",
    "#iterator = twitter_stream.statuses.filter(locations=Santa_Monica+','+\\\n",
    "#                                          Midland_Odessa+','+Dallas+','+\\\n",
    "#                                          Sacramento_east+','+SFO)\n",
    "iterator = twitter_stream.statuses.filter(locations=los_angeles)\n",
    "tweet_count =2\n",
    "\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "for tweet in iterator:\n",
    "    \n",
    "    if tweet['coordinates'] !='None': \n",
    "        tweet_count -= 1  \n",
    "        print(tweet)\n",
    "        print(tweet['coordinates'])\n",
    "    if tweet_count <= 0:\n",
    "        break   \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dc30ff00fb58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bounding_box'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coordinates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "tweet['place']['bounding_box']['coordinates'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet['bounding_box']['coordinates']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
