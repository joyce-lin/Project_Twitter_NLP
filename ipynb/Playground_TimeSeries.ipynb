{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.en import English\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_select = '''\n",
    "select created_at, location, tweet_content, cleaned_tweet, vector from tweets;\n",
    "'''\n",
    "\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "cur = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "cur.execute(sql_select)\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['created_datetime'] = pd.to_datetime(df['created_at'])\n",
    "df['year'] = df.created_datetime.apply(lambda x: x.year)\n",
    "df['month'] = df.created_datetime.apply(lambda x: x.month)\n",
    "df['day'] = df.created_datetime.apply(lambda x: x.day)\n",
    "df['dayofweek'] = df.created_datetime.apply(lambda x: x.dayofweek)\n",
    "df['hour'] = df.created_datetime.apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390117"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['exit 11b',\n",
       "       'this joint  #losfeliz #hidden #bar #losangeles #hollywood #birthday @ tenants of the trees https://t.co/ni3nzvu754',\n",
       "       'i have the best glam team around ðŸ˜»ðŸ”¥ https://t.co/f3jvqdyfgw',\n",
       "       'i feel attacked @shmasonayala',\n",
       "       'ok but when he was up in the majors he was terrible https://t.co/iw1hhx4vr6',\n",
       "       'my prayers have been answered. #thanksgod #pokemonsunmoon #pokemon #harambe https://t.co/ymyrxhseap',\n",
       "       \"i look like i'm balding. #wtf? shiiiet... still handsome tho. #ftw #podcast @itsdpd #skincareâ€¦ https://t.co/ajjx26dhwq\",\n",
       "       \"@gameofthrones it's almost fucking summer!\",\n",
       "       \"me at oomf cause ew i can't believe i... https://t.co/prd6xnl6at\",\n",
       "       '@venicemase  just checking to see if your good after eating 13 donuts in 5 minutes.  #tde the doubt eater'], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Paris_accords_df = df[(df['created_datetime'] > '2017-06-01 14:35:00')][(df['created_datetime'] < '2017-06-03 14:35:00')]\n",
    "Paris_accords_df['tweet_content'].sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'never have i supported the united nations carbon climate agenda nor other banking aspects of the climate agenda.'], dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paris_accords = Paris_accords_df[Paris_accords_df['tweet_content'].str.contains(('paris|climate'))]\n",
    "paris_accords.reset_index(inplace = True)\n",
    "paris_accords['cleaned_tweet'].sample(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "A_index = list(range(paris_accords.shape[0]))\n",
    "random.shuffle(A_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 200\n",
    "A1_index = []\n",
    "for i in range(n):\n",
    "    A1_index.append(A_index.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = paris_accords.iloc[A1_index,:]\n",
    "A2 = paris_accords.iloc[A_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2414, 12)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 12)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 300)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1.reset_index(inplace = True)\n",
    "A1_vec = np.array([nlp(i).vector for i in A1['cleaned_tweet']])\n",
    "A1_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2414, 300)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2.reset_index(inplace = True)\n",
    "A2_vec = np.array([nlp(i).vector for i in A2['cleaned_tweet']])\n",
    "A2_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_paris_accords = Paris_accords_df[~Paris_accords_df['cleaned_tweet'].str.contains(('paris|climate|accord|trump'))]\n",
    "non_paris_accords.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B_index = list(range(non_paris_accords.shape[0]))\n",
    "random.shuffle(B_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "B1_index = []\n",
    "for i in range(n):\n",
    "    B1_index.append(B_index.pop())\n",
    "m = A2.shape[0]\n",
    "B2_index = []\n",
    "for i in range(m):\n",
    "    B2_index.append(B_index.pop())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = non_paris_accords.iloc[B1_index,:]\n",
    "B2 = non_paris_accords.iloc[B2_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 300)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B1.reset_index(inplace = True)\n",
    "B1_vec = np.array([nlp(i).vector for i in B1['cleaned_tweet']])\n",
    "B1_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2414, 300)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2.reset_index(inplace = True)\n",
    "B2_vec = np.array([nlp(i).vector for i in B2['cleaned_tweet']])\n",
    "B2_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A1_vec_mean = np.average(A1_vec, axis=0)\n",
    "A2_vec_mean = np.average(A2_vec, axis=0)\n",
    "B1_vec_mean = np.average(B1_vec, axis=0)\n",
    "B2_vec_mean = np.average(B2_vec, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99916667]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(A1_vec_mean.reshape(1,-1),A2_vec_mean.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99919271]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(B2_vec_mean.reshape(1,-1),B1_vec_mean.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97586632]], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(A1_vec_mean.reshape(1,-1),B1_vec_mean.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97923732]], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(A2_vec_mean.reshape(1,-1),B2_vec_mean.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Similarity_score(text):\n",
    "    wiki_cat_df = pd.DataFrame(list(cli.wiki_mongo_database.wiki_cat_collection.find({})))\n",
    "    #cat_vecs = np.array([nlp(i).vector for i in wiki_cat_df['text']])\n",
    "    r = redis.StrictRedis(redis_ip)\n",
    "    cat_vecs = pickle.loads(r.get('nlp_cat_vecs'))\n",
    "    similarity_score={}\n",
    "    for j in range(len(cat_vecs)):\n",
    "        similarity = cosine_similarity(cat_vecs[j].reshape(1,-1),nlp(text).vector.reshape(1,-1))\n",
    "        similarity_score[(wiki_cat_df['category'][j])] = round(similarity[0][0],3)\n",
    "        cs_s_df = pd.DataFrame.from_dict(similarity_score,orient='index')\n",
    "        cs_s_df.columns = ['score']\n",
    "        cs_s_df = cs_s_df.sort_values('score',ascending=False)\n",
    "    return cs_s_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_select = '''\n",
    "select id, tweet_content, count(*) from tweets group by id, tweet_content HAVING count(*) > 1 order by id\n",
    "'''\n",
    "\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "cur = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "cur.execute(sql_select)\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_select = '''\n",
    "select id, tweet_content from tweets where id in \n",
    "        ('870369089822236672', '870369123766685698', '870412757312647168',\n",
    "       '870736125140156416', '870736377163333632', '870736526442876929',\n",
    "       '870736651051442176', '870736815195475968', '870736826973036544',\n",
    "       '870737064672636928', '870737118456201216', '870737249171685376',\n",
    "       '870737290254929920', '870737449386876928', '870737688697196545',\n",
    "       '870737824277962752', '870738170819641345', '870739370730377216',\n",
    "       '870739784519393280', '870740002203881472', '870740231019937792',\n",
    "       '870740967396999168', '870740985059303424', '870741079565324288',\n",
    "       '870741317936062464', '870826652044939264', '871071496130646016',\n",
    "       '871107396843614208', '871414307308789760', '871865745357058049') order by id\n",
    "'''\n",
    "\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "cur = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "cur.execute(sql_select)\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_delete = '''\n",
    "alter table tweets \n",
    "alter column id set not null,\n",
    "ADD PRIMARY KEY (id);   \n",
    "'''\n",
    "alter column id type integer,\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "cur = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "cur.execute(sql_delete)\n",
    "conn.commit()\n",
    "#rows = cur.fetchall()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "BEGIN;\n",
    "CREATE INDEX ON tweets (id); \n",
    "COMMIT;\n",
    "'''\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "cur = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "cur.execute(sql)\n",
    "conn.commit()\n",
    "#rows = cur.fetchall()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
